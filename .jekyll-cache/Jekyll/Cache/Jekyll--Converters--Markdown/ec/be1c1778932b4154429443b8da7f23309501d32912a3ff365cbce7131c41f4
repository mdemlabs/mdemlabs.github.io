I"<h3> Korelasyon nedensellik değildir! </h3>

<p>On yıldan daha kısa bir süre içinde, bilgisayarlar hastalıkları teşhis etmede, dilleri tercüme etmede ve konuşmayı yazıya dökmede son derece başarılı hale geldi. Karmaşık strateji oyunlarında insanları geride bırakabiliyor, trafikte insan sürücü olmaksızın arabalar gidebiliyor yada gerçekliğinden şüphe edilmeyecek kadar sahici insan yüzleri oluşturabiliyor.</p>

<p>
  <kbd>
    <img src="/images2/why.jpg" width="600" />
  </kbd>
</p>

<p>Yine de bu etkileyici başarılara rağmen, yapay zekanın göze çarpan zayıflıkları var.</p>

<p>Günümüzde iş ve endüstride uygulanan yapay zeka, nedenleri değil korelasyonları bulur. İnsanlar neden sonuç ilişkisi kurmaya odaklıdır. Belirli bir sistemin nasıl çalıştığını bilmeseler bile, genellikle o sistemin nasıl çalıştığına dair bir teorisi, modeli vardır. İnşa edilen modeller, insanların sebep ve sonuç hakkında akıl yürütmesini mümkün kılar. Biz böyle çalıştığımız için, AI’nın da bu şekilde çalıştığını varsayma eğilimindeyiz. Bu doğru değil. Bir insan olarak bizler nedenler hakkında akıl yürütebiliriz, ancak bugün uygulandığı gibi Yapay Zeka kendi başına nedensel ilişkiler kuramaz.</p>

<p>“Sebep ve sonucu anlamak, sağduyu dediğimiz şeyin büyük bir yönü ve bugün yapay zeka sistemlerinin fikrinin olmadığı bir alan”, diyor Elias Bareinboim, Columbia Üniversitesi’ndeki yeni Nedensel Yapay Zeka Laboratuvarı’nın yöneticisi olarak. Bu labaratuvar bir sonraki adımı atmak için çalışıyor: bilgisayarları, insanların nedensel keşifleri için daha kullanışlı araçlar yapmak.</p>

<p>AI’nın korelasyonları tespit etme yeteneği - örneğin bulutların yağmuru daha olası hale getirmesi - nedensel muhakemenin en basit seviyesidir. Son on yılda derin öğrenme olarak bilinen algoritmalar sayesinde Yapay Zeka alanında patlama yaşandı. Tanıdık durumlar hakkında çok sayıda veri verildiğinde, bu yöntem çok iyi tahminlere yol açabilir. Bir bilgisayar, belirli semptomları olan bir hastanın belirli bir hastalığa sahip olma olasılığını hesaplayabilir, çünkü aynı semptomlara sahip diğer binlerce hatta milyonlarca kişinin bu hastalığa sahip olduğunu öğrenmiştir.</p>

<p>Ancak, bilgisayarlar neden-sonuç ilişkisilarini görmekte daha iyi hale gelmezse yapay zekadaki ilerlemenin duracağına dair artan bir fikir birliği var. Makineler belirli şeylerin başka şeylere yol açtığını kavrayabilseler, her şeyi her zaman yeniden öğrenmek zorunda kalmazlar - bir alanda öğrendiklerini alıp diğerine uygulayabilirlerdi. Ve makineler sağduyuyu kullanabilirlerse, aptalca hatalar yapma olasılıklarının çok düşük olacacağından, kendi başlarına eylemlerde bulunmaları için onlara daha fazla güvenebiliriz.</p>

<p>Bugünün yapay zekası, belirli bir eylemden ne sonuçlanacağını anlamak için yalnızca sınırlı bir yeteneğe sahiptir. Makinelerin satranç ve Go gibi oyunlarda ustalaşmasına izin veren bir teknik olan pekiştirmeli öğrenmede bir sistem, hangi hareketlerin esasen kazanmalarına neden olacağını anlamak için kapsamlı deneme yanılma kullanır. Ancak bu yaklaşım, gerçek dünyada daha karmaşık ortamlarda işe yaramıyor.</p>

<p>Daha da yüksek bir nedensel düşünme seviyesi, olayların neden olduğu hakkında mantık yürütme ve “eğer” sorusu sorma yeteneği olacaktır. Bir klinik araştırma sırasında bir hasta ölür; deneysel tıbbın hatası mıydı yoksa başka bir şey mi? Okul sınav puanları düşüyor; onları en çok hangi politika değişiklikleri iyileştirir? Bu tür bir akıl yürütme, yapay zekanın mevcut kapasitesinin çok ötesindedir.</p>

<p>Örneğin, Cambridge, Massachusetts’teki bir şirket olan <strong>GNS Healthcare</strong>, umut verici görünen deneyler hakkında araştırmacılara tavsiyelerde bulunmak için üzerinde çalıştıkları yazılım, yüzlerce hatta binlerce değişken arasında hangi değişkenlerin diğer değişkenler üzerinde en fazla etkiye sahip olduğunu tespit etmek için büyük miktarda veriyi elemeye yarıyor. Bir projede GNS, bir tür kan kanseri olan “multipl miyelom” üzerinde çalışan araştırmacılarla çalıştı. Araştırmacılar, hastalığı olan bazı hastaların, yaygın bir tedavi şekli olan kök hücre nakli yaptıktan sonra neden diğerlerinden daha uzun yaşadığını bilmek istediler. Yazılım, 30.000 değişkenli verileri karıştırdı ve özellikle nedensel olma ihtimali yüksek görünen birkaçına işaret etti. Hastalıktaki biyoistatistikçiler ve uzmanlar, özellikle tek bir noktaya odaklandılar: Hastanın vücudundaki belirli bir proteinin seviyesi. Araştırmacılar daha sonra, proteini olan hastaların tedaviden gerçekten daha fazla fayda sağlayıp sağlamadığını görmek için hedefli bir klinik araştırma yürütebilirler. Bu şekilde araştırmacılar çok ciddi zaman kazanabilirler.</p>

<p>Montreal Üniversitesi’nde derin öğrenme konusundaki çalışmaları nedeniyle 2018 Turing Ödülü’nü paylaşan bir bilgisayar bilimcisi olan <strong>Yoshua Bengio</strong>, “meta-learning” yapmak için derin öğrenmenin kalbindeki yazılım olan sinir ağlarını kullanmaya çalışıyor. Durum şu anda olduğu gibi, insanların ne zaman dans ettiğini algılamak için bir sinir ağı istiyorsanız, ona pek çok dansçı resmi göstermiş olursunuz. İnsanların ne zaman koştuğunu belirlemesini istiyorsanız, ona birçok koşucu resmi göstermiş olursunuz. Sistem, bir kişinin ellerinin ve kollarının pozisyonları gibi görüntülerde farklı olma eğiliminde olan özellikleri belirleyerek koşucuları dansçılardan ayırmayı öğrenecekti. Ancak Bengio, veri setlerinde benzer veya “değişmez” olan şeyleri analiz ederek dünya hakkındaki temel bilgilerin toplanabileceğine dikkat çekiyor. Belki bir sinir ağı, bacak hareketlerinin fiziksel olarak hem koşmaya hem de dansa neden olduğunu öğrenebilir. Belki de bu örnekleri ve insanlara yerden sadece birkaç adım öteyi gösteren diğer pek çok örneği gördükten sonra, bir makine sonunda yerçekimi ve bunun insan hareketini nasıl sınırladığını anlayacaktır. Zamanla, veri kümeleri arasında tutarlı olan değişkenler hakkında yeterli meta-öğrenmeyle, bir bilgisayar birçok alanda yeniden kullanılabilecek nedensel bilgi edinebilir.</p>

<p><strong>Judea Pearl</strong>, zengin bir sebep ve sonuç anlayışına sahip olmadan yapay zekanın gerçekten zeki olamayacağını söylüyor. Yapay bir genel zeka (General AI) için nedensel akıl yürütme yeterli olmasa da gerekli, çünkü bilmenin ötesinde bilincin ve farkındalığın özünde yer alan iç gözlemi mümkün kılacağını belirtiyor. Pearl, “Ya” soruları “bilimin, ahlaki tutumların, özgür iradenin, bilincin yapı taşlarıdır” diyor. Judea Pearl’un başta çok satan kitabı “<strong>The Book of Why: The New Science of Cause and Effect</strong>” olmak üzere nedensellik üzerine pek çok yayını var ve bu konuda dünyadaki en önemli figürlerden biri. Aşağıdaki video’da nedensellik üzerine bir konuşması var;</p>

<iframe width="800" height="600" src="https://www.youtube.com/embed/ZaPV1OSEpHw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Kaynakça:</p>
<ol>
  <li><a href="https://www.manning.com/books/succeeding-with-ai">“Succeeding with AI”, Veljko Krunic</a></li>
  <li><a href="https://www.technologyreview.com/2020/02/19/868178/what-ai-still-cant-do/">“What AI still can’t do”, MIT Technology Review</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Meta_learning_(computer_science)">Meta-learning, Wikipedia</a></li>
</ol>

:ET